from aiogram import Dispatcher, types
from aiogram.dispatcher import FSMContext
import os
import tempfile
from src.handlers.common import TranslatorStates
from src.services.ai import AITranslator
from src.services.tts import TTSService
from src.services.speech import SpeechService

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å—ã
translator = AITranslator()
tts_service = TTSService()
speech_service = SpeechService()  # –°–æ–∑–¥–∞–µ–º –æ–¥–∏–Ω —Ä–∞–∑

async def process_voice_message(message: types.Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    temp_voice_path = None
    wav_path = None
    status_message = None
    
    try:
        # –°–æ–æ–±—â–∞–µ–º –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        status_message = await message.answer("üéß –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ (—Ä–µ–∂–∏–º–µ –ø–µ—Ä–µ–≤–æ–¥–∞)
        current_state = await state.get_state()
        is_ru_to_th = current_state == TranslatorStates.waiting_for_text_ru_th.state
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        voice_file = await message.voice.get_file()
        voice_path = voice_file.file_path
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        temp_fd, temp_voice_path = tempfile.mkstemp(suffix='.ogg')
        os.close(temp_fd)
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        await message.bot.download_file(voice_path, temp_voice_path)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OGG –≤ WAV
        wav_path = temp_voice_path + '.wav'
        os.system(f'ffmpeg -i "{temp_voice_path}" -ar 16000 -ac 1 "{wav_path}" -y')
        
        # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å
        text = speech_service.recognize_speech(wav_path, is_russian=is_ru_to_th)
        
        if not text:
            await status_message.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
            return
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        await message.answer(f"üéØ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{text}")
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º
        await status_message.edit_text("üîÑ –ü–µ—Ä–µ–≤–æ–¥–∏–º...")
        translated = await translator.translate(
            text,
            "Russian" if is_ru_to_th else "Thai",
            "Thai" if is_ru_to_th else "Russian"
        )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥
        await message.answer(
            f"{'üáπüá≠' if is_ru_to_th else 'üá∑üá∫'} {translated}"
        )
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        audio_path = await tts_service.text_to_speech(
            translated,
            is_russian=not is_ru_to_th
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –Ω–µ –ø—É—Å—Ç–æ–π
        if os.path.exists(audio_path) and os.path.getsize(audio_path) > 0:
            with open(audio_path, 'rb') as audio:
                await message.answer_voice(audio)
        else:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –∞—É–¥–∏–æ
        if os.path.exists(audio_path):
            os.unlink(audio_path)
        
    except Exception as e:
        print(f"Error processing voice message: {e}")
        if status_message:
            await status_message.edit_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è")
    
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        if temp_voice_path and os.path.exists(temp_voice_path):
            os.unlink(temp_voice_path)
        if wav_path and os.path.exists(wav_path):
            os.unlink(wav_path)

def register_handlers(dp: Dispatcher):
    dp.register_message_handler(
        process_voice_message,
        content_types=[types.ContentType.VOICE],
        state=[
            TranslatorStates.waiting_for_text_ru_th,
            TranslatorStates.waiting_for_text_th_ru
        ]
    )
